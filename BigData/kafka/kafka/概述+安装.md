## 1.kafka概述

### 1.1定义

![](D:\typroa.md\image\Snipaste_2022-04-18_17-17-51.png)

言外之意：kafka将zookeeper踢出了轮换。

### 1.2 消息队列

目 前 企 业 中 比 较 常 见 的 消 息 队 列 产 品 主 要 有     Kafka 、 ActiveMQ 、 RabbitMQ 、RocketMQ 等。

#### 1.2.1 传统消息队列的应用场景

传统的消息队列的主要应用场景包括：`缓存/消峰`、`解耦`和`异步通信`。

![](D:\typroa.md\image\Snipaste_2022-04-18_17-19-45.png)

![](D:\typroa.md\image\Snipaste_2022-04-18_17-20-10.png)

![](D:\typroa.md\image\Snipaste_2022-04-18_17-21-04.png)

#### 1.2.2 消息队列的两种模式

![](D:\typroa.md\image\Snipaste_2022-04-18_17-21-35.png)

![](D:\typroa.md\image\Snipaste_2022-04-18_17-22-14.png)

（1）**Producer**：消息生产者，就是向  Kafka broker 发消息的客户端。

（2）**Consumer**：消息消费者，向 Kafka broker 取消息的客户端。

（3）**Consumer Group（CG）**： 消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，`一个分区只能由一个组内消费者消费`；`消费者组之间互不影响`。所有的消费者都属于某个消费者组，即`消费者组是逻辑上的一个订阅者`。

（4）**Broker**：`一台  Kafka 服务器就是一个  broker`。一个集群由多个  broker 组成。一个broker 可以容纳多个 topic。

（5）**Topic**：可以理解为一个队列（`缓冲区，数据分区组`），生产者和消费者面向的都是一个  topic。

（6）**Partition**：为了实现扩展性，一个非常大的topic 可以分布到多个broker（即服务器）上，一个  topic 可以分为多个  partition，每个 partition 是一个有序的队列。

（7）**Replica**：副本。一个   topic 的每个分区都有若干个副本，一个   Leader 和若干个Follower。

（8）**Leader**：每个分区多个副本的“`主`”，生产者发送数据的对象，以及消费者消费数据的对象都是 Leader。

（9） **Follower**： 每个分区多个副本中的“`从`”，实时从    Leader 中同步数据，保持和Leader 数据的`同步`。`Leader 发生故障时，某个 Follower 会成为新的 Leader。`



## 2.集群安装

### 2.1 安装部署

#### 2.1.1 集群规划

| hadoop102 | hadoop103 | hadoop104 |
| --------- | --------- | --------- |
| zk        | zk        | zk        |
| kafka     | kafka     | kafka     |

#### 2.1.2 集群部署

##### 0）官方下载地址：

http://kafka.apache.org/downloads.html

##### 1）解压安装包

```shell
tar -zxvf kafka_2.12-3.0.0.tgz -C /opt/module/
```

##### 2）修改解压后的文件名称

```shell
mv kafka_2.12-3.0.0/ kafka
```

##### 3）进入到/opt/module/kafka 目录，修改配置文件

```shell
[hou@hadoop102 kafka]$cd config/
[hou@hadoop102 kafka]vim server.properties
```

更改以下内容：以横线标记

```properties
---------------------------------------
#broker的全局唯一编号，不能重复，只能是数字。
broker.id=0
---------------------------------------
#处理网络请求的线程数量 
num.network.threads=3 
#用来处理磁盘 IO的线程数量 
num.io.threads=8
#发送套接字的缓冲区大小
socket.send.buffer.bytes=102400 
#接收套接字的缓冲区大小
socket.receive.buffer.bytes=102400 
#请求套接字的缓冲区大小
socket.request.max.bytes=104857600
#kafka 运行日志(数据)存放的路径，路径不需要提前创建，kafka 自动帮你创建，可以配置多个磁盘路径，路径与路径之间可以用"，"分隔
---------------------------------------
log.dirs=/opt/module/kafka/datas
---------------------------------------
#topic在当前 broker上的分区个数 
num.partitions=1
#用来恢复和清理 data 下数据的线程数量
num.recovery.threads.per.data.dir=1 
# 每个  topic创建时的副本数，默认时  1个副本 
offsets.topic.replication.factor=1 
#segment文件保留的最长时间，超时将被删除 
log.retention.hours=168
#每个  segment 文件的大小，默认最大 1G 
log.segment.bytes=1073741824
# 检查过期数据的时间，默认  5分钟检查一次是否数据过期 
log.retention.check.interval.ms=300000
----------------------------------------------
#配置连接 Zookeeper 集群地址（在  zk根目录下创建/kafka，方便管理）
zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka
-----------------------------------------------
```

##### 4）分发安装包

```shell
xsync kafka/
```

5）分别在  hadoop103 和  hadoop104 上修改配置文件/opt/module/kafka/config/server.properties中的 `broker.id=1、broker.id=2`

**`注：broker.id 不得重复，整个集群中唯一。`**

##### 6）配置环境变量

（1）在/etc/profile.d/my_env.sh 文件中增加 kafka 环境变量配置

```shell
sudo vim /etc/profile.d/my_env.sh
```

增加如下内容：

```shell
#KAFKA_HOME
export KAFKA_HOME=/opt/module/kafka 
export PATH=$PATH:$KAFKA_HOME/bin
```

（2）刷新一下环境变量。

```shell
source /etc/profile
```

（3）分发环境变量文件到其他节点，并  source

```shell
sudo    /home/atguigu/bin/xsync /etc/profile.d/my_env.sh
[hou@hadoop103 module]$ source /etc/profile
[hou@hadoop103 module]$source /etc/profile
```

##### 7）启动集群

（1）先启动 Zookeeper 集群，然后启动 Kafka。

```shell
[hou@hadoop102kafka]$ zk.sh start
```

（2）依次在 hadoop102、hadoop103、hadoop104 节点上启动  Kafka。

```shell
[atguigu@hadoop102  kafka]$  bin/kafka-server-start.sh  -daemon config/server.properties
[atguigu@hadoop103 kafka]$  bin/kafka-server-start.sh  -daemon config/server.properties
[atguigu@hadoop104 kafka]$  bin/kafka-server-start.sh  -daemon config/server.properties
```

`注意：配置文件的路径要能够到  server.properties。`，需要覆盖默认的配置文件。



##### 8）关闭集群

```shell
[atguigu@hadoop102 kafka]$ bin/kafka-server-stop.sh 
[atguigu@hadoop103 kafka]$ bin/kafka-server-stop.sh 
[atguigu@hadoop104 kafka]$ bin/kafka-server-stop.sh
```



#### 2.1.3 集群启停脚本

1）在/home/atguigu/bin 目录下创建文件 kf.sh 脚本文件

```shell
[atguigu@hadoop102 bin]$ vim kf.sh
```

脚本如下：

```shell
#! /bin/bash 
case $1 in
"start"){
for i in hadoop102 hadoop103 hadoop104 
do
echo " --------启动    $i Kafka-------"
ssh  $i  "/opt/module/kafka/bin/kafka-server-start.sh  -
daemon /opt/module/kafka/config/server.properties" 
done
};;
"stop"){
for i in hadoop102 hadoop103 hadoop104 
do
echo " --------停止    $i Kafka-------"
ssh $i "/opt/module/kafka/bin/kafka-server-stop.sh " 
done
};; 
esac
```

##### 2）添加执行权限

```shell
chmod +x kf.sh
```

##### 3）启动集群命令

```
kf.sh start
```

##### 4）停止集群命令

```shell
kf.sh stop
```

`注意：停止 Kafka 集群时，一定要等 Kafka 所有节点进程全部停止后再停止 Zookeeper集群。因为 Zookeeper 集群当中记录着 Kafka 集群相关信息，Zookeeper 集群一旦先停止，Kafka 集群就没有办法再获取停止进程的信息，只能手动杀死 Kafka 进程了。`