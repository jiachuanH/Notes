#  1.Kafka 消费方式



pull（ 拉 ） 模式：
`consumer采用从broker中主动拉取数据。 Kafka采用这种方式。`

push（推）模式：
`Kafka没有采用这种方式，因为由broker决定消息发送速率`，很难适应所有消费者的消费速率。例如推送的速度是50m/s， 
Consumer1、Consumer2就来不及处理消息。

`pull模式不足之处是，如果Kafka没有数据，消费者可能会陷入循环中，一直返回空数据`。

<img src="D:\typroa.md\image\Snipaste_2022-04-26_17-27-45.png" style="zoom: 50%;" />

# 2.Kafka 消费者工作流程

![](D:\typroa.md\image\Snipaste_2022-04-26_17-28-49.png)

## 2.1 消费者总体工作流程

消费者或消费者组向kafka集群拉取指定分区的数据，`消费者组的每个组成员只能拉取不同分区的数据，不能拉取相同分区的数据，这样会造成重复消费，后续需要数据去重，不利于管理`。消费者组可以看成一个完整的集体。

消费者断线重连消费数据，需要依赖于offset，在kafka0.9版本之前offset数存储在zookeeper上，这样如果消费者会和zookeeper进行大量的交互，可能会造成大量的网络数据传输频繁。

## 2.2 消费者组原理

**Consumer Group（CG）**：消费者组，由多个consumer组成。形成一个消费者组的条件，是**所有消费者的groupid相同**。

消费者组内每个消费者负责`消费不同分区`的数据，`一个分区只能由一个组内消费者消费`。

`消费者组之间互不影响`。所有的消费者都属于某个消费者组，即`消费者组是逻辑上的一个订阅者`。

第一组：一个消费者（消费者组中只有一个消费者）消费多个分区内的数据，在自定义消费者的时候会设置一个参数groupid这个是必须的，无论消费者组中有多少消费者都需要设置groupid。

第二组：两个消费者消费不同分区中的数据，分担了单个消费者的压力

第四组：消费者>分区，造成了消费者闲置。

第五组:不同消费者组之间不会相互影响。

![](D:\typroa.md\image\Snipaste_2022-04-26_18-41-38.png)

![](D:\typroa.md\image\Snipaste_2022-04-26_18-42-03.png)

### 消费者组初始化流程

1.coordinator：辅助实现消费者组的初始化和分区的分配，每个broker上都有coordinator。

coordinator节点选择 = groupid的hashcode值 % `50`（  `__consumer_offsets的分区数量`）

例如：  groupid的hashcode值 = 1，1% 50 = 1，那么`__consumer_offsets 主题的1号分区，在哪个broker上，就选择这个节点的coordinator作为这个消费者组的协调器`。消费者组下的所有的消费者提交offset的时候就往这个分区去提交offset。

![](D:\typroa.md\image\Snipaste_2022-04-26_21-14-24.png)

（1）根据groupid的hash值/50 得出__consumer_offsets-partition所在的broker节点，该broker节点上的coordinator辅助消费者组

（2）具有相同groupid的消费者组向该coordinator发送joinGroup请求

（3）coordinator随机选出一个consumer作为该消费者组的Leader，并且将要消费的topic发送给leader消费者

（4）Leader指定消费计划（分区分配情况，也就是消费者组成员要消费的对象）

（5）leader向coordinator发送消费计划

（6）coordinator向follower consumer发送消费计划

`（7）每个消费者组中的消费者成员，都会向coordinator保持心跳（3s一次），如果超出45s会将该消费者组成员移除消费者组，同时会触发任务再平衡。或者，如果消费者组成员的消费时间过长（5分钟），也会触发再平衡。`**面试重点**



### 消费者详细消费流程

![](D:\typroa.md\image\Snipaste_2022-04-26_21-34-36.png)

- 消费者组首先创建一个`ConsumerNetworkClient`，主要用于与kafka集群进行`交互`

- 消费者组向ConsumerNetworkClient发送消费请求`setFetches（）`，并且抓取数据的初始化

  触发多个参数设置：

  `Fetch.min.bytes每批次最小抓取大小，默认1字节`
  `fetch.max.wait.ms一批数据最小值未达到的超时时间，默认500ms，如果设置的每批次抓取的数据过大，而kafka集群发送的数据小，达不到每批次抓取数据的值，那么当达到设定的抓取时间，就会强行将积累的数据作为一个批次`
  `Fetch.max.bytes每批次最大抓取大小，默认50m`

- ConsumerNetworkClient向kafka集群发送`send（）`请求

-  使用回调方法（`onsuccess（）`）将数据拉取到`消息队列``completedFetches （queue）`，

- 消费者组一次最大拉去`500`条数据

- 数据首先进行`反序列化（parseRecord）然后经过拦截器（interceptors）最后consumer处理数据`。



## 2.3 消费者重要参数

![](D:\typroa.md\image\Snipaste_2022-04-27_21-27-35.png)

![](D:\typroa.md\image\Snipaste_2022-04-27_21-27-52.png)

# 3.消费者 API

## 3.1 独立消费者案例（订阅主题）

### 1）需求：

创建一个独立消费者，消费  first 主题中数据。

![](D:\typroa.md\image\Snipaste_2022-04-27_21-29-05.png)

`注意：在消费者API 代码中必须配置消费者组id。命令行启动消费者不填写消费者组id 会被自动填写随机的消费者组  id。`

### 2）实现步骤

- 创建propertise对象 (使用ConsumerConfig. 设置各种参数)
  - `连接集群`
  - `将kv反序列化`
  - `创建消费者组GROUP_ID`
- 创建kafkaConsumer对象

- 订阅主题

  - `subscribe（Collection<String> topics）,需要创一个arraylist存储主题名字`

- 消费数据

  **以下带注释的代码都是重点**

- ```java
  package com.atguigu.kafka.consumer;
  
  import org.apache.kafka.clients.consumer.*;
  import org.apache.kafka.common.serialization.StringDeserializer;
  
  import java.time.Duration;
  import java.util.ArrayList;
  import java.util.Properties;
  
  /**
   * @author shkstart
   * @create 2022 - 04 - 27 - 14:25
   */
  public class CustomConsumer {
      public static void main(String[] args) {
          //0.配置文件
          Properties properties = new Properties();
          //和集群连接 必须
          properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,"hadoop102:9092,hadoop103:9092");
          //将kv进行反序列化 必须
          properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
          properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
          //创建消费者组的GROUP_ID ,必须
          properties.put(ConsumerConfig.GROUP_ID_CONFIG, "test");
   
          //1.创建消费者
          KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
          //2.订阅主题
          //在这里我们只订阅一个主题，在这个集合里面可以订阅多个集合
          ArrayList<String> topics = new ArrayList<>();
          topics.add("first");
          kafkaConsumer.subscribe(topics);
          //3.消费数据
          while (true){
              ConsumerRecords<String, String> consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(1));
              //将拉取的数据进行打印
              for (ConsumerRecord<String, String> consumerRecord:consumerRecords){
                  System.out.println(consumerRecord);
              }
          }
      }
  }
  
  ```

### 3）测试

（1）在  IDEA 中执行消费者程序。

（2）在  Kafka 集群控制台，创建  Kafka 生产者，并输入数据。

（3）在  IDEA 控制台观察接收到的数据。

```shell
ConsumerRecord(topic = first, partition = 1, leaderEpoch = 3, offset = 0, CreateTime = 1629160841112, serialized key size = -1, serialized value size = 5, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hello)
```

## 3.2 独立消费者案例（订阅分区）

### 1）需求：

创建一个独立消费者，消费 first 主题 0 号分区的数据。

![](D:\typroa.md\image\Snipaste_2022-04-27_21-36-49.png)

### 2）实现步骤

- 创建propertise对象 (使用ConsumerConfig设置各种参数)

  - 连接集群
  - 将kv反序列化
  - 创建消费者组GROUP_ID

- 创建kafkaConsumer对象

- 订阅主题分区

  - `assign(Collection<topicPartition> partitions)，创建一个arraylist存储topictition对象，topictition对象存储了主题和分区信息。`

- 消费数据

  `以下带注释的代码都是重点`

```java
package com.atguigu.kafka.consumer;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.ArrayList;
import java.util.Properties;

/**
 * @author shkstart
 * @create 2022 - 04 - 27 - 15:18
 */
public class CustConsumerPartiton {
    public static void main(String[] args) {
        //0.创建配置文件
        Properties properties = new Properties();
        //连接集群
        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092,hadoop103:9092");
        //kv反序列化
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        //创建GROUPID
        properties.put(ConsumerConfig.GROUP_ID_CONFIG,"test");
        //1.创建消费者
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        //2.订阅主题的分区
        //创建主题分区的数组,arraylist 的泛型是TopicPartition
        ArrayList<TopicPartition> topicPartitions = new ArrayList<>();
        topicPartitions.add(new TopicPartition("first",0));
        consumer.assign(topicPartitions);
        //3.消费数据
        while(true){
            ConsumerRecords<String, String> poll = consumer.poll(Duration.ofSeconds(1));
            for (ConsumerRecord<String, String> consumerRecord:poll){
                System.out.println(consumerRecord);
            }
        }
    }
}

```

### 3）测试

（1）在  IDEA 中执行消费者程序。

（2）在  IDEA 中执行生产者程序  CustomProducerCallback()在控制台观察生成几个0号分区的数据。

（3）在  IDEA 控制台，观察接收到的数据，只能消费到 0 号分区数据表示正确。

```java
ConsumerRecord(topic = first, partition = 0, leaderEpoch = 14, offset = 381, CreateTime = 1636791331386, serialized key size = - 1, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = atguigu 0)

ConsumerRecord(topic = first, partition = 0, leaderEpoch = 14, offset = 382, CreateTime = 1636791331397, serialized key size = - 1, serialized value size = 9, headers = RecordHeaders(headers = 
[], isReadOnly = false), key = null, value = atguigu 1)
```

## 3.3 消费者组案例

### 1）需求：

测试同一个主题的分区数据，只能由一个消费者组中的一个消费。

![](D:\typroa.md\image\Snipaste_2022-04-27_21-46-43.png)

### 2）案例实操

（1）复制一份基础消费者的代码，在IDEA 中同时启动，即可启动同一个消费者组中的两个消费者。

同时开启三个

```java
package com.atguigu.kafka.consumer;

import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.ArrayList;
import java.util.Properties;

/**
 * @author shkstart
 * @create 2022 - 04 - 27 - 14:25
 */
public class CustomConsumer {
    public static void main(String[] args) {
        //0.配置文件
        Properties properties = new Properties();
        //和集群连接 必须
        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,"hadoop102:9092,hadoop103:9092");
        //将kv进行反序列化 必须
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        //创建消费者组的GROUP_ID ,必须
        properties.put(ConsumerConfig.GROUP_ID_CONFIG, "test");
        //修改分区分配策略
        ArrayList<String> startegys = new ArrayList<>();
        startegys.add("org.apache.kafka.clients.consumer.StickyAssignor");
        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, startegys);
        //1.创建消费者
        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
        //2.订阅主题
        //在这里我们只订阅一个主题，在这个集合里面可以订阅多个集合
        ArrayList<String> topics = new ArrayList<>();
        topics.add("first");
        kafkaConsumer.subscribe(topics);
        //3.消费数据
        while (true){
            ConsumerRecords<String, String> consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(1));
            //将拉取的数据进行打印
            for (ConsumerRecord<String, String> consumerRecord:consumerRecords){
                System.out.println(consumerRecord);
            }
        }
        //4.这个是让poll停下的，暂时不用

    }
}

```

（2）启动代码中的生产者发送消息，在   IDEA 控制台即可看到两个消费者在消费不同分区的数据（如果只发生到一个分区，可以在发送时增加延迟代码  Thread.sleep(2);）。

```java
ConsumerRecord(topic = first, partition = 0, leaderEpoch = 2, 
offset = 3, CreateTime = 1629169606820, serialized key size = -1, 
serialized value size = 8, headers = RecordHeaders(headers = [], 
isReadOnly = false), key = null, value = hello1)

ConsumerRecord(topic = first, partition = 1, leaderEpoch = 3, 
offset = 2, CreateTime = 1629169609524, serialized key size = -1, 
serialized value size = 6, headers = RecordHeaders(headers = [], 
isReadOnly = false), key = null, value = hello2)

ConsumerRecord(topic = first, partition = 2, leaderEpoch = 3, 
offset = 21, CreateTime = 1629169611884, serialized key size = - 
serialized value size = 6, headers = RecordHeaders(headers = [], 
isReadOnly = false), key = null, value = hello3)
```

（3）重新发送到一个全新的主题中，由于默认创建的主题分区数为 1，可以看到只能有一个消费者消费到数据。

# 4.生产经验——分区的分配以及再平衡

1、一个consumer group中有多个consumer组成，一个 topic有多个partition组成，现在的问题是，`到底由哪个consumer来消费哪个partition的数据`。

2、Kafka有四种主流的分区分配策略：  `Range、RoundRobin、Sticky、CooperativeSticky。`
可以通过配置参数`partition.assignment.strategy`，修改分区的分配策略。默认策略是Range +  CooperativeSticky。Kafka可以同时使用多个分区分配策略。

| 参数名称                      | 描述                                                         |
| ----------------------------- | ------------------------------------------------------------ |
| heartbeat.interval.ms         | Kafka 消费者和 coordinator 之间的心跳时间，默认 `3s`。该 条 目 的 值 必 须 小 于     session.timeout.ms ， 也 不 应 该 高 于session.timeout.ms（45S） 的  1/3。 |
| session.timeout.ms            | Kafka 消费者和  coordinator 之间连接超时时间，默认  `45s`。超过该值，该消费者被移除，消费者组执行再平衡 |
| max.poll.interval.ms          | 消费者处理消息的最大时长，`默认是   5 分钟`。超过该值，该消费者被移除，消费者组执行再平衡。 |
| partition.assignment.strategy | 消费者分区分配策略，默认策略是Range+CooperativeSticky。Kafka 可以同时使用多个分区分配策略。可 以 选 择 的 策 略 包 括 ： `Range 、 RoundRobin 、 Sticky 、CooperativeSticky` |

## 4.1 Range 以及再平衡（大哥多劳动）

### 1）Range 分区策略原理

![](D:\typroa.md\image\Snipaste_2022-04-28_17-15-19.png)

Range 是对每个  topic 而言的。

首先对同一个 topic 里面的`分区按照序号进行排序`，并对`消费者按照字母顺序进行排序`。

假如现在有  7 个分区，3 个消费者，排序后的分区将会是0,1,2,3,4,5,6；消费者排序完之后将会是C0,C1,C2。

通过 `partitions数/consumer`数 来`决定每个消费者应该消费几个分区`。`如果除不尽，那么前面几个消费者将会多消费 1 个分区，消费的分区号是连续的`。

例如，7/3 = 2 余 1 ，除不尽，那么 消费者 C0 便会多消费 1 个分区。 8/3=2余2，除不尽，那么C0和C1分别多 
消费一个。

`注意：`如果只是针对  1 个  topic 而言，C0消费者多消费1个分区影响不是很大。但是`如果有 N 多个  topic，那么针对每个topic，消费者C0都将会多消费N个分区。`

`容易产生数据倾斜`

### 2）Range 分区分配策略案例

（1）修改主题 first 为 7 个分区

```shell
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --alter --topic first --partitions 7
```

`命令行只能增加分区数，不能减少分区数`

（2）复制   CustomConsumer 类 ， 创建   CustomConsumer2。 这 样 可 以 由 三 个 消 费 者CustomConsumer、CustomConsumer1、CustomConsumer2 组成消费者组，组名都为“test”，同时启动 3 个消费者。具有相同Group_id的消费者会组成消费者组。

```java
package com.atguigu.kafka.consumer;

import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.ArrayList;
import java.util.Properties;

/**
 * @author shkstart
 * @create 2022 - 04 - 27 - 14:25
 */
public class CustomConsumer {
    public static void main(String[] args) {
        //0.配置文件
        Properties properties = new Properties();
        //和集群连接 必须
        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,"hadoop102:9092,hadoop103:9092");
        //将kv进行反序列化 必须
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        //创建消费者组的GROUP_ID ,必须
        properties.put(ConsumerConfig.GROUP_ID_CONFIG, "test");
  
        //1.创建消费者
        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
        //2.订阅主题
        //在这里我们只订阅一个主题，在这个集合里面可以订阅多个集合
        ArrayList<String> topics = new ArrayList<>();
        topics.add("first");
        kafkaConsumer.subscribe(topics);
        //3.消费数据
        while (true){
            ConsumerRecords<String, String> consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(1));
            //将拉取的数据进行打印
            for (ConsumerRecord<String, String> consumerRecord:consumerRecords){
                System.out.println(consumerRecord);
            }
        }
        //4.这个是让poll停下的，暂时不用

    }
}

```

`说明：Kafka 默认的分区分配策略就是 Range + CooperativeSticky，所以不需要修改策略。`

（4）观看 3 个消费者分别消费哪些分区的数据。

### 3）Range 分区分配再平衡案例

（1）停止掉 0 号消费者，快速重新发送消息观看结果（45s 以内，越快越好）。

1 号消费者：消费到 3、4 号分区数据。 

2 号消费者：消费到 5、6 号分区数据。

0 号消费者的任务会`整体`被分配到 1 号消费者或者 2 号消费者。

`说明：0 号消费者挂掉后，消费者组需要按照超时时间  45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他  broker 执行。`

（2）再次重新发送消息观看结果（45s 以后）。

1 号消费者：消费到 0、1、2、3 号分区数据。 

2 号消费者：消费到 4、5、6 号分区数据。

`说明：消费者 0 已经被踢出消费者组，所以重新按照  range 方式分配。`

## 4.2 RoundRobin 以及再平衡

### 1）RoundRobin 分区策略原理

![](D:\typroa.md\image\Snipaste_2022-04-28_17-36-24.png)

RoundRobin 针对集群中所有`Topic而言。`

RoundRobin 轮询分区策略，`是把所有的 partition 和所有的consumer 都列出来`，然后按照 `hashcode 进行排序`，最后通过`轮询算法来分配 partition 给到各个消费者。`

`其实就是通过hash值将topic分区和消费者组成员排序之后，逐个给消费者组成员分配主题分区。`

### 2）RoundRobin 分区分配策略案例

（1）依次在    CustomConsumer、CustomConsumer1、CustomConsumer2 三个消费者代码中修改分区分配策略为 RoundRobin。

```java
package com.atguigu.kafka.consumer;

import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.ArrayList;
import java.util.Properties;

/**
 * @author shkstart
 * @create 2022 - 04 - 27 - 14:25
 */
public class CustomConsumer {
    public static void main(String[] args) {
        //0.配置文件
        Properties properties = new Properties();
        //和集群连接 必须
        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,"hadoop102:9092,hadoop103:9092");
        //将kv进行反序列化 必须
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        //创建消费者组的GROUP_ID ,必须
        properties.put(ConsumerConfig.GROUP_ID_CONFIG, "test");
        
        
        //修改分区分配策略
        ArrayList<String> round = new ArrayList<>();
        round.add("org.apache.kafka.clients.consumer.RoundRobinAssignor");
        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, round);
        
        
        //1.创建消费者
        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
        //2.订阅主题
        //在这里我们只订阅一个主题，在这个集合里面可以订阅多个集合
        ArrayList<String> topics = new ArrayList<>();
        topics.add("first");
        kafkaConsumer.subscribe(topics);
        //3.消费数据
        while (true){
            ConsumerRecords<String, String> consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(1));
            //将拉取的数据进行打印
            for (ConsumerRecord<String, String> consumerRecord:consumerRecords){
                System.out.println(consumerRecord);
            }
        }
        //4.这个是让poll停下的，暂时不用

    }
}
```

round分区分配策略代码与range分区分配策略不同的事，需要将ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG设置为`"org.apache.kafka.clients.consumer.RoundRobinAssignor"`全类名。

### （2）重启 3 个消费者，重复发送消息的步骤，观看分区结果。

![](D:\typroa.md\image\Snipaste_2022-04-28_17-48-41.png)

![](D:\typroa.md\image\Snipaste_2022-04-28_17-52-04.png)

![](D:\typroa.md\image\Snipaste_2022-04-28_17-53-18.png)

与猜想的结果一样，1、4分区被`1`消费者组成员消费，2、5分区被`2`消费者组成员消费 ，0、3、6分区被`3`消费者组成员消费 。

### 3）RoundRobin 分区分配再平衡案例

（1）停止掉 0 号消费者，快速重新发送消息观看结果（45s 以内，越快越好）。 

1 号消费者：消费到  2、5 号分区数据

2 号消费者：消费到  4、1 号分区数据

0 号消费者的任务会按照  `RoundRobin 的方式，把数据轮询分成  0 、6 和  3 号分区数据，分别由 1 号消费者或者 2 号消费者消费。`

`说明：0 号消费者挂掉后，消费者组需要按照超时时间  45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他  broker 执行。`

（2）再次重新发送消息观看结果（45s以后）。 

1 号消费者：消费到  0、2、4、6 号分区数据 

2 号消费者：消费到  1、3、5 号分区数据

`说明：消费者 0 已经被踢出消费者组，所以重新按照  RoundRobin 方式分配。`

## 4.3 Sticky 以及再平衡

粘性分区定义：可以理解为分配的结果带有“粘性的”。即在执行一次新的分配之前，考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。

粘性分区是 Kafka 从 0.11.x 版本开始引入这种分配策略，`首先会尽量均衡的放置分区到消费者上面`，在出现同一消费者组内消费者出现问题的时候，会`尽量保持原有分配的分区不变化`。这种分区分配策略打比方说：7个分区，3个消费者，一次消费者组消费会话中，会出现3、2、2分配策略，当消费者组成员再次消费时还会消费该分配策略的主题分区。

### 1）需求

设置主题为  first，7 个分区；准备  3 个消费者，采用粘性分区策略，并进行消费，观察消费分配情况。然后再停止其中一个消费者，再次观察消费分配情况。

### 2）步骤

（1）修改分区分配策略为粘性。

注意：3 个消费者都应该注释掉，之后重启3个消费者，如果出现报错，全部停止等会再重启，或者修改为全新的消费者组。

```java
package com.atguigu.kafka.consumer;

import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.ArrayList;
import java.util.Properties;

/**
 * @author shkstart
 * @create 2022 - 04 - 27 - 14:25
 */
public class CustomConsumer {
    public static void main(String[] args) {
        //0.配置文件
        Properties properties = new Properties();
        //和集群连接 必须
        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,"hadoop102:9092,hadoop103:9092");
        //将kv进行反序列化 必须
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        //创建消费者组的GROUP_ID ,必须
        properties.put(ConsumerConfig.GROUP_ID_CONFIG, "test");
        
        
        //修改分区分配策略
        ArrayList<String> startegys = new ArrayList<>();
        startegys.add("org.apache.kafka.clients.consumer.StickyAssignor");
        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, startegys);
        
        
        //1.创建消费者
        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
        //2.订阅主题
        //在这里我们只订阅一个主题，在这个集合里面可以订阅多个集合
        ArrayList<String> topics = new ArrayList<>();
        topics.add("first");
        kafkaConsumer.subscribe(topics);
        //3.消费数据
        while (true){
            ConsumerRecords<String, String> consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(1));
            //将拉取的数据进行打印
            for (ConsumerRecord<String, String> consumerRecord:consumerRecords){
                System.out.println(consumerRecord);
            }
        }
        //4.这个是让poll停下的，暂时不用

    }
}

```

此分区分配策略，使用的是"org.apache.kafka.clients.consumer.StickyAssignor"类。

```java
 //修改分区分配策略
        ArrayList<String> startegys = new ArrayList<>();
        startegys.add("org.apache.kafka.clients.consumer.StickyAssignor");
        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, startegys);
```

### 3）Sticky 分区分配再平衡案例

（1）停止掉 0 号消费者，快速重新发送消息观看结果（45s 以内，越快越好）。

1 号消费者：消费到  2、5、3 号分区数据。

2 号消费者：消费到  4、6 号分区数据。

`0 号消费者的任务会按照粘性规则，尽可能均衡的随机分成0 和1 号分区数据，分别由 1 号消费者或者 2 号消费者消费。`

说明：0 号消费者挂掉后，消费者组需要按照超时时间  45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他  broker 执行。 

（2）再次重新发送消息观看结果（45s 以后）。 

1 号消费者：消费到  2、3、5 号分区数据。 

2 号消费者：消费到  0、1、4、6 号分区数据。

`说明：消费者 0 已经被踢出消费者组，所以重新按照粘性方式分配。`

# 5.offset 位移

## 重点：代码的注释，以及代码的步骤

## 5.1 offset 的默认维护位置

![](D:\typroa.md\image\Snipaste_2022-04-28_18-21-26.png)

__consumer_offsets 主题里面采用 key 和 value 的方式存储数据。key 是 group.id+topic+分 区 号 ， value 就 是 当 前 offset 的值。 每 隔 一 段 时 间 ， kafka 内 部 会 对 这 个 topic 进行`compact`(压缩，更新数据)，也就是每个 group.id+topic+分区号就保留最新数据。

### 1）消费  offset 案例

（0）思想：__consumer_offsets 为 Kafka 中的  topic，那就可以通过消费者进行消费。

（1）在配置文件    `config/consumer.properties` 中添加配置    `exclude.internal.topics=false`，默认是 `true`，表示不能消费系统主题。为了查看该系统主题数据，所以该参数修改为 `false`。

（2）采用命令行方式，创建一个新的 topic。

（3）启动生产者往  atguigu 生产数据。

（4）启动消费者消费  atguigu 数据。

`注意：指定消费者组名称，更好观察数据存储位置（key 是 group.id+topic+分区号）。`

（5）查看消费者`消费主题`__consumer_offsets。

```shell
bin/kafka-console-consumer.sh --topic __consumer_offsets  --bootstrap-server  hadoop102:9092  --consumer.config    config/consumer.properties "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" --from-beginning
```

## 5.2 自动提交  offset

为了使我们能够专注于自己的业务逻辑，Kafka提供了自动提交offset的功能。

自动提交offset的相关参数：

`enable.auto.commit：是否开启自动提交offset功能，默认是true`

`auto.commit.interval.ms：自动提交offset的时间间隔，默认是5s`

![](D:\typroa.md\image\Snipaste_2022-04-29_20-12-14.png)

| 参数名称                | 描述                                                         |
| ----------------------- | ------------------------------------------------------------ |
| enable.auto.commit      | 默认值为 true，消费者会自动周期性地向kafka主题提交`偏移量`。 |
| auto.commit.interval.ms | 如果设置了   enable.auto.commit  的值为    true，   则该值定义了消费者偏移量向 Kafka 提交的频率，`默认  5s。` |

### 1）消费者自动提交offset

步骤：

- 创建Properties对象
- 创建连接
- 反序列化
- 创建group_id
- 开启自动提交offset,ENABLE_AUTO_COMMIT_CONFIG=true，true是String or object都行
- 创建consumer对象
- 订阅主题的方法：subscribe()
- 消费数据
  - 拉取数据
  - 打印数据

```java
package com.atguigu.kafka.consumer;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.ArrayList;
import java.util.Properties;

/**
 * @author shkstart
 * @create 2022 - 04 - 29 - 8:37
 */
public class CustomConsumerAutoOffset {
    public static void main(String[] args) {
        //创建Properties对象
        Properties properties = new Properties();
        //创建连接
        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092,hadoop103:9092");
        //反序列化
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        //创建group_id
        properties.put(ConsumerConfig.GROUP_ID_CONFIG, "test1");
        
        ---------------------------------
        //开启自动提交offset,true是String or object都行
        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
        //提交offset时间周期1000ms，默认是5s。
        properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 1000);
        
        
        //创建consumer对象
        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
        //订阅主题的方法：subscribe()
        ArrayList<String> list = new ArrayList<>();
        list.add("first");
        kafkaConsumer.subscribe(list);
        
        //消费数据
        while (true) {
            //拉取数据
            ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(1));
            //打印数据
            for (ConsumerRecord<String, String> record : records) {
                System.out.println(record);
            }
        }
        //
    }
}
```

## 5.3 手动提交  offset

虽然自动提交offset十分简单便利，但由于其是基于时间提交的，开发人员难以把握offset提交的时机。因此Kafka还提供了手动提交offset的API。

手动提交offset的方法有两种：分别是`commitSync（同步提交）`和`commitAsync（异步提交）`。两者的相同点是，都会将本次提交的一批数据`最高的偏移量提交`；不同点是，`同步提交阻塞当前线程，一直到提交成功`，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而`异步提交则没有失败重试机制，故有可能提交失败`。

`commitSync（同步提交）：必须等待offset提交完毕，再去消费下一批数据。`

`commitAsync（异步提交）：发送完提交offset请求后，就开始消费下一批数据了。`

![](D:\typroa.md\image\Snipaste_2022-04-29_20-19-37.png)

### 1）同步提交  offset

由于同步提交    offset 有失败重试机制，故更加可靠，但是由于一直等待提交结果，提交的效率比较低。以下为同步提交  offset 的示例。

步骤：

- 创建Properties对象

- 创建连接

- 反序列化

- 创建group_id

- 开启手动提交offset,ENABLE_AUTO_COMMIT_CONFIG=false，false是String or object都行

- 创建consumer对象

- 订阅主题的方法：subscribe()

- 确定得到分区分配策略，只有得到分区分配策略，才能指定位置的消费offset

  - 催化得到分区分配策略                                                                                                      

- 消费数据

  - 拉取数据

  - 打印数据

    

```java
package com.atguigu.kafka.consumer;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.ArrayList;
import java.util.HashSet;
import java.util.Properties;
import java.util.Set;

/**
 * @author shkstart
 * @create 2022 - 04 - 29 - 8:37
 */
public class CustomConsumerByHandAsync {
    public static void main(String[] args) {
        //创建Properties对象
        Properties properties = new Properties();
        //创建连接
        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092,hadoop103:9092");
        //反序列化
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        //创建group_id
        properties.put(ConsumerConfig.GROUP_ID_CONFIG, "test");
//        //开启自动提交offset,true是String or object都行
//        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
//        //提交offset时间周期1000ms，默认是5s。
//        properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 1000);
        //创建consumer对象
        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
        //订阅主题
        ArrayList<String> list = new ArrayList<>();
        list.add("first");
        kafkaConsumer.subscribe(list);
-----------------------------------------------------------------------------------------------------
        //得到分区信息才进行指定offset消费，assignment是分区分配信息（分区信息，有多少分区，分区的尾）
        Set<TopicPartition> assignment = new HashSet<>();
        //如果assignment为空，说明coordinator还没将分区分配（消费者组成员消费的分区，其实消费的任务）信息发给consumer follower，这时需要推动分区分配信息发送
        while (assignment.size() == 0) {
            //推动器
            kafkaConsumer.poll(Duration.ofSeconds(1));
            //检验消费者是否拿到分区分配信息（也包含着分区信息）
            assignment = kafkaConsumer.assignment();
        }
        
        //遍历所有分区，指定从offset  1700的位置进行消费 使用seek，指定开始消费位置
        for (TopicPartition tp : assignment) {
            kafkaConsumer.seek(tp, 700);
        }
        
-----------------------------------------------------------------------------------------------------
        //消费数据
        while (true) {
            //拉取数据
            ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(1));
            //打印数据
            for (ConsumerRecord<String, String> record : records) {
                System.out.println(record);
            }
            //消费数据后进行同步，等到同步offset完成之后再进行消费数据
            kafkaConsumer.commitAsync();
        }
        //
    }
}

```

### 2）异步提交 offset

虽然同步提交    offset 更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会受到很大的影响。因此更多的情况下，会选用异步提交  offset 的方式。

```java
package com.atguigu.kafka.consumer;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.ArrayList;
import java.util.HashSet;
import java.util.Properties;
import java.util.Set;

/**
 * @author shkstart
 * @create 2022 - 04 - 29 - 8:37
 */
public class CustomConsumerByHandSync {
    public static void main(String[] args) {
        //创建Properties对象
        Properties properties = new Properties();
        //创建连接
        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092,hadoop103:9092");
        //反序列化
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        //创建group_id
        properties.put(ConsumerConfig.GROUP_ID_CONFIG, "test");
//        //开启自动提交offset,true是String or object都行
//        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
//        //提交offset时间周期1000ms，默认是5s。
//        properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 1000);
        //创建consumer对象
        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
        //订阅主题
        ArrayList<String> list = new ArrayList<>();
        list.add("first");
        kafkaConsumer.subscribe(list);
---------------------------------------------------------------------------------------------
        //得到分区信息才进行指定offset消费，assignment是分区分配信息（分区信息，有多少分区，分区的尾）
        Set<TopicPartition> assignment = new HashSet<>();
        //如果assignment为空，说明coordinator还没将分区分配（消费者组成员消费的分区，其实消费的任务）信息发给consumer follower，这时需要推动分区分配信息发送
        while (assignment.size() == 0) {
            //推动器
            kafkaConsumer.poll(Duration.ofSeconds(1));
            //检验消费者是否拿到分区分配信息（也包含着分区信息）
            assignment = kafkaConsumer.assignment();
        }
        //遍历所有分区，指定从offset  1700的位置进行消费
        for (TopicPartition tp : assignment) {
            kafkaConsumer.seek(tp, 700);
        }
-----------------------------------------------------------------------------------------------
        //消费数据
        while (true) {
            //拉取数据
            ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(1));
            //打印数据
            for (ConsumerRecord<String, String> record : records) {
                System.out.println(record);
            }
            //消费一批数据立刻进行同步，不等同步是否完成
            kafkaConsumer.commitSync();
            
        }
        //
    }
}

```

## 5.4 指定  Offset 消费

`auto.offset.reset = earliest | latest | none`   默认是 latest。

当   Kafka 中没有初始偏移量（消费者组第一次消费）或服务器上不再存在当前偏移量时（例如该数据已被删除），该怎么办？

（1）`earliest`：自动将偏移量重置为最早的偏移量，`--from-beginning`。

（2）`latest（默认值）`：自动将偏移量重置为最新偏移量。

（3）none：如果未找到消费者组的先前偏移量，则向消费者抛出异常。

![](D:\typroa.md\image\Snipaste_2022-04-29_20-42-26.png)

（4）任意指定 offset 位移开始消费

```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;
import java.time.Duration;
import java.util.ArrayList;
import java.util.HashSet;
import java.util.Properties;
import java.util.Set;
public class CustomConsumerSeek {
public static void main(String[] args) {
// 0  配置信息
Properties properties = new Properties(); 
// 连接
properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, 
"hadoop102:9092");
// key value 反序列化
properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
properties.put(ConsumerConfig.GROUP_ID_CONFIG, "test2"); 
// 1 创建一个消费者
KafkaConsumer<String,   String>   kafkaConsumer   =   new KafkaConsumer<>(properties);
    // 2 订阅一个主题
ArrayList<String> topics = new ArrayList<>(); 
topics.add("first");
kafkaConsumer.subscribe(topics);
    //获取分区分配策略
Set<TopicPartition> assignment= new HashSet<>(); 
while (assignment.size() == 0) {
kafkaConsumer.poll(Duration.ofSeconds(1));
// 获取消费者分区分配信息（有了分区分配信息才能开始消费） 
assignment = kafkaConsumer.assignment();
}
    
// 遍历所有分区，并指定  offset从  1700 的位置开始消费 
for (TopicPartition tp: assignment) {
kafkaConsumer.seek(tp, 1700); 
}
// 3 消费该主题数据 
while (true) {
ConsumerRecords<String,  String>  consumerRecords  = 
kafkaConsumer.poll(Duration.ofSeconds(1));
for (ConsumerRecord<String, String> consumerRecord : 
consumerRecords) {
System.out.println(consumerRecord); 
}
} 
}
}
```

`注意：每次执行完，需要修改消费者组名；`

## 5.5 指定时间消费

需求：在生产环境中，会遇到最近消费的几个小时数据异常，想重新按照时间消费。例如要求按照时间消费前一天的数据，怎么处理？

操作步骤

步骤：

- 创建Properties对象
- 创建连接
- 反序列化
- 创建group_id
- 开启手动提交offset,ENABLE_AUTO_COMMIT_CONFIG=false，false是String or object都行
- 创建consumer对象
- 订阅主题的方法：subscribe()
- 确定得到分区分配策略，只有得到分区分配策略，才能指定位置的消费offset
  - 催化得到分区分配策略 
  - 使用map1存储（分区，指定的分区的时间【比如一天前】）
  -  将map1存储的java类型的Long型数据转换为kafka类型的Long型数据，并且使用map2接收数据map（topicpartition，OffsetAndTimestamp）
  - 取出map2中的时间数据OffsetAndTimestamp
  - 确定消费的位置使用OffsetAndTimestamp.offset()将Long数据转换为offset。                                                                
- 消费数据
  - 拉取数据
  - 打印数据

```java
package com.atguigu.kafka.consumer;

import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.utils.Time;

import java.time.Duration;
import java.util.*;

/**
 * 指定时间的offset消费
 *
 * @author shkstart
 * @create 2022 - 04 - 29 - 8:37
 */
public class CustomConsumerForTime {
    public static void main(String[] args) {
        //创建Properties对象
        Properties properties = new Properties();
        //创建连接
        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092,hadoop103:9092");
        //反序列化
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        //创建group_id
        properties.put(ConsumerConfig.GROUP_ID_CONFIG, "test");


//        //开启自动提交offset,true是String or object都行
//        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
//        //提交offset时间周期1000ms，默认是5s。
//        properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 1000);
        //创建consumer对象


        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
        //订阅主题
        ArrayList<String> list = new ArrayList<>();
        list.add("first");
        kafkaConsumer.subscribe(list);

-----------------------------------------------------------------------------------------------------
        //得到分区信息才进行指定offset消费，assignment是分区分配信息（分区信息，有多少分区，分区的尾）
        Set<TopicPartition> assignment = new HashSet<>();
        //如果assignment为空，说明coordinator还没将分区分配（消费者组成员消费的分区，其实消费的任务）信息发给consumer follower，这时需要推动分区分配信息发送
        while (assignment.size() == 0) {
            //推动器
            kafkaConsumer.poll(Duration.ofSeconds(1));
            //检验消费者是否拿到分区分配信息（也包含着分区信息）
            assignment = kafkaConsumer.assignment();
        }
        //将topic分区和分区的时间进行Map存储，便于查找分区时能够直接找到指定的时间,
        HashMap<TopicPartition, Long> timestampToSearch = new HashMap<TopicPartition, Long>();
        //遍历所有分区
        for (TopicPartition tp : assignment) {
            timestampToSearch.put(tp, System.currentTimeMillis() - 1 * 24 * 3600 * 1000);
        }
        //获取从前一天开始消费的每个分区的offset，就是将Long型的Time转换成kafka的Long offsets型数据
        Map<TopicPartition, OffsetAndTimestamp> offsets = kafkaConsumer.offsetsForTimes(timestampToSearch);
        //遍历每个分区，取出对应的每个分区的Long型时间数据
        for (TopicPartition topicPartition : assignment) {
            //取出所有的Long型时间数据
            OffsetAndTimestamp offsetAndTimestamp = offsets.get(topicPartition);
            if (offsetAndTimestamp != null) {
                //将kafka Long型数据转换成offset，并且设置consumer起始消费的eoffset位置
                kafkaConsumer.seek(topicPartition, offsetAndTimestamp.offset());
            }
        }
-----------------------------------------------------------------------------------------------------
        //消费数据
        while (true) {
            //拉取数据
            ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(1));
            //打印数据
            for (ConsumerRecord<String, String> record : records) {
                System.out.println(record);
            }
            kafkaConsumer.commitSync();
        }
        //
    }
}

```

## 5.6 漏消费和重复消费

**重复消费**：已经消费了数据，但是  offset 没提交。

**漏消费**：先提交 offset 后消费，有可能会造成数据的漏消费。

### （1）场景1：重复消费。

​		自动提交offset引起。

自动提交的时候因为是每5s提交一次，但是提交成功之后2s又进行数据写到磁盘上。当consumer挂掉之后，重启会从上次的offset位置进行消费。

![](D:\typroa.md\image\Snipaste_2022-04-29_21-20-32.png)

### （2）场景2：漏消费。

设置offset为手动提交，当offset被提交时，数据还在内存中未落盘，此时刚好消费者线程被kill掉，那么offset已经提交，但是数据未处理，导致这部分内存中的数据丢失。

![](D:\typroa.md\image\Snipaste_2022-04-29_21-26-38.png)

思考：怎么能做到既不漏消费也不重复消费呢？详看消费者事务。

# 6 生产经验——消费者事务

如果想完成Consumer端的精准一次性消费，那么需要`Kafka消费端将消费过程和提交offset过 程 做 原 子 绑 定` 。 此 时 我 们 需 要 将 Kafka的 offset保 存 到 支 持 事 务 的 自 定 义 介 质 （ 比如`MySQL`）。这部分知识会在后续项目部分涉及。

![](D:\typroa.md\image\Snipaste_2022-04-29_21-58-04.png)

生产端=》集群

集群=》消费者端

消费者端=》框架

# 7.生产经验——数据积压（消费者如何提高吞吐量）

![](D:\typroa.md\image\Snipaste_2022-04-29_22-01-48.png)

生产者=》集群：4个参数提高吞吐量（批次大小，等待时间，压缩算法，缓冲区大小）

集群=》消费者：两个参数（拉取条数，最大批次数据）

增加主题分区，增加消费者组的成员











