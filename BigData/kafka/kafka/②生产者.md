## 1.生产者消息发送流程

### 1.1 发送原理

在消息发送的过程中，涉及到了两个线程——`main 线程和 Sender` 线程。在 main 线程中创建了`一个双端队列 RecordAccumulator`。main 线程将消息发送给 `RecordAccumulator`，Sender 线程不断从 `RecordAccumulator` 中`拉取`消息发送到 Kafka Broker。

![]()<img src="D:\typroa.md\image\Snipaste_2022-04-19_21-54-07.png" alt="Snipaste_2022-04-19_21-54-07" style="zoom:67%;" />

### 1.2 生产者重要参数列表

| 参数名称                              | 描述                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| bootstrap.servers                     | 生产者连接集群所需的 broker 地 址 清 单 。 例如 <br/>hadoop102:9092,hadoop103:9092,hadoop104:9092， 可 以 <br/>设置 1 个或者多个，中间用逗号隔开。注意这里并非需要所有的   broker 地址，因为生产者从给定的    broker <br/>里查找到其他 broker 信息。 |
| key.serializer 和 value.serializer    | 指定发送消息的   key 和   value 的序列化类型。一定要写 <br/>全类名。 |
| buffer.memory                         | RecordAccumulator 缓冲区总大小，`默认  32m。`                |
| batch.size                            | 缓冲区一批数据最大值，`默认 16k`。适当增加该值，可 <br/>以提高吞吐量，但是如果该值设置太大，会导致数据 <br/>传输延迟增加。 |
| linger.ms                             | 如果数据迟迟未达到 batch.size，sender 等待 linger.time <br/>之后就会发送数据。单位 ms`，默认值是 0ms`，表示没 <br/>有延迟。生产环境建议该值大小为 5-100ms 之间。 |
| acks                                  | 0：生产者发送过来的数据，不需要等数据落盘应答。 <br/>1：生产者发送过来的数据，Leader 收到数据后应答。 <br/>-1（all）：生产者发送过来的数据，Leader+和 isr 队列 <br/>里面的所有节点收齐数据后应答。`默认值是-1，-1 和 <br/>all 是等价的。` |
| max.in.flight.requests.per.connection | 允许最多没有返回  ack 的次数，`默认为  5，`开启幂等性 <br/>要保证该值是 1-5 的数字。 |
| retries                               | 当消息发送出现错误的时候，系统会重发消息。retries <br/>表示重试次数。`默认是  int 最大值，2147483647。` <br/>如果设置了重试，还想保证消息的有序性，需要设置 <br/>MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1 <br/>否则在重试此失败消息的时候，其他的消息可能发送 <br/>成功了。 |
| retry.backoff.ms                      | 两次重试之间的时间间隔，默认是 100ms。                       |
| enable.idempotence                    | 是否开启幂等性，默认  true，开启幂等性。                     |
| compression.type                      | 生产者发送的所有数据的压缩方式。`默认是    none`，也 <br/>就是不压缩。<br/>支持压缩类型：`none、gzip、snappy、lz4 和  zstd`。 |
|                                       |                                                              |

## 2.异步发送 API

### 2.1 普通异步发送

1）需求：创建 Kafka 生产者，采用异步的方式发送到  Kafka Broker

<img src="D:\typroa.md\image\Snipaste_2022-04-20_14-21-04.png" style="zoom:50%;" />

2）代码编写

 （1）创建工程 kafka
		（2）导入依赖

```xml
<dependencies> 
<dependency>
<groupId>org.apache.kafka</groupId> 
<artifactId>kafka-clients</artifactId> 
<version>3.0.0</version>
</dependency> 
</dependencies>
```

（3）创建包名：com.atguigu.kafka.producer

（4）编写不带回调函数的  API 代码

```java
package com.atguigu.kafka.producer;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

/**
 * @author shkstart
 * @create 2022 - 04 - 19 - 17:10
 */
public class producer1 {
    public static void main(String[] args) {
        //2.创建生产者配置对象
        Properties properties = new Properties();
        //配置对象添加配置信息
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092");
        //key,value序列化（必要条件）
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        //1.创建kafka生产者对象
        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(properties);
        //3.调用send方法，发送信息
        for (int i=0;i<=5;i++){
            producer.send(new ProducerRecord<>("first","atguigu"+i));
        }
        //4.关闭资源
        producer.close();

    }
}

```

测试：

①在 hadoop102 上开启 Kafka 消费者。

```shell
bin/kafka-console-consumer.sh   --bootstrap-server hadoop102:9092 --topic first
```

②在  IDEA 中执行代码，观察  hadoop102 控制台中是否接收到消息。

```shell
atguigu 0
atguigu 1
atguigu 2
atguigu 3
atguigu 4
```

### 2.2 带回调函数的异步发送

`其实就是在send函数中，只用第二个参数callback，实现该类并且重写方法。`

回调函数会在 producer 收到 ack 时调用，为异步调用，该方法有两个参数，分别是元数据信息（RecordMetadata）和异常信息（Exception），如果 Exception 为 null，说明消息发送成功，如果 Exception 不为 null，说明消息发送失败。

<img src="D:\typroa.md\image\Snipaste_2022-04-20_14-24-11.png" style="zoom:50%;" />

```java
package com.atguigu.kafka.producer;

import org.apache.kafka.clients.Metadata;
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

/**
 * @author shkstart
 * @create 2022 - 04 - 19 - 17:10
 */
public class producerCallback {
    public static void main(String[] args) {
        //2.创建生产者配置对象
        Properties properties = new Properties();
        //配置对象添加配置信息
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092");
        //key,value序列化（必要条件）
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        //1.创建kafka生产者对象
        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(properties);
        //3.调用send方法，发送信息
        for (int i=0;i<=5;i++){
            producer.send(new ProducerRecord<>("first", "atguigu" + i), new Callback() {
                @Override
                public void onCompletion(RecordMetadata recordMetadata, Exception e) {
                    if(e==null){
                        System.out.println("主题为："+ recordMetadata.topic()+"分区为："+recordMetadata);
                    }
                }
            });
            // 延迟一会会看到数据发往不同分区 
			Thread.sleep(2);
        }
        //4.关闭资源
        producer.close();

    }
}

```

测试：

①在 hadoop102 上开启 Kafka 消费者。

```shell
bin/kafka-console-consumer.sh   --bootstrap-server hadoop102:9092 --topic first
```

②在  IDEA 中执行代码，观察  hadoop102 控制台中是否接收到消息。

```shell
atguigu 0
atguigu 1
atguigu 2
atguigu 3
atguigu 4
```

③在  IDEA 控制台观察回调信息。

```shell
主题：first->分区：0 
主题：first->分区：0 
主题：first->分区：1 
主题：first->分区：1 
主题：first->分区：1
```

## 3.同步发送API

<img src="D:\typroa.md\image\Snipaste_2022-04-20_16-54-04.png" style="zoom:50%;" />

只需在异步发送的基础上，在send（）之后调用一下  get()方法即可。send（）.get()。

```java
package com.atguigu.kafka.producer;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;
import java.util.concurrent.ExecutionException;

/**同步发送，在异步发送的基础上将send使用get（）
 * @author shkstart
 * @create 2022 - 04 - 19 - 17:10
 */
public class producerSync {
    public static void main(String[] args) throws ExecutionException, InterruptedException {
        //2.创建生产者配置对象
        Properties properties = new Properties();
        //配置对象添加配置信息
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092");
        //key,value序列化（必要条件）
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        //1.创建kafka生产者对象
        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(properties);
        //3.调用send方法，发送信息
        for (int i=0;i<=5;i++){
            producer.send(new ProducerRecord<>("first","atguigu"+i)).get();
        }
        //4.关闭资源
        producer.close();

    }
}

```

测试：

①在 hadoop102 上开启 Kafka 消费者。

```shell
bin/kafka-console-consumer.sh   --bootstrap-server hadoop102:9092 --topic first
```

②在  IDEA 中执行代码，观察  hadoop102 控制台中是否接收到消息。

```shell
atguigu 0
atguigu 1
atguigu 2
atguigu 3
atguigu 4
```

## 4.生产者分区

### 4.1分区好处

（1）便于合理使用存储资源，每个Partition在一个Broker上存储，可以把海量的数据按照分区切割成一块一块数据存储在多台Broker上。合理控制分区的任务，可以实现负载均衡的效果。

（2）提高并行度，生产者可以以分区为单位发送数据；消费者可以以分区为单位进行消费数据。

![](D:\typroa.md\image\Snipaste_2022-04-20_16-59-33.png)

### 4.2 生产者发送消息的分区策略

#### 1）默认的分区器 DefaultPartitioner

在 IDEA 中 ctrl +n，全局查找 DefaultPartitioner。

```java
/**
* The default partitioning strategy: 
* <ul>
* <li>If a partition is specified in the record, use it
* <li>If no partition is specified but a key is present choose a 
partition based on a hash of the key
* <li>If no partition or key is present choose the sticky 
partition that changes when the batch is full.
*
* See KIP-480 for details about sticky partitioning. 
*/
public class DefaultPartitioner implements Partitioner {
… … 
}
```

![](D:\typroa.md\image\Snipaste_2022-04-20_17-00-39.png)

#### 2）案例一

`将数据发往指定 partition 的情况下，例如，将所有数据发往分区 1 中。`

```java
package com.atguigu.kafka.producer;

import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

/**
 * 按照key将数据发送到指定的分区
 * @author shkstart
 * @create 2022 - 04 - 19 - 17:10
 */
public class producerPartiton {
    public static void main(String[] args) {
        //2.创建生产者配置对象
        Properties properties = new Properties();
        //配置对象添加配置信息
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092");
        //key,value序列化（必要条件）
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        //1.创建kafka生产者对象
        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(properties);
        //3.调用send方法，发送信息
        for (int i=0;i<=5;i++){
            
            
            //根据指定的分区，将数据传输到指定的分区
            
            
            producer.send(new ProducerRecord<>("first", 1, "atguigu" + i), new Callback() {
            //只有key根据key的hash值 确定分区的情况
            // producer.send(new ProducerRecord<>("first", "atguigu", "atguigu" + i), new Callback() {
                @Override
                public void onCompletion(RecordMetadata recordMetadata, Exception e) {
                    if (e==null){
                        System.out.println("主题是"+recordMetadata.topic()+"分区为"+recordMetadata.partition());
                    }
                }
            });
        }
        //4.关闭资源
        producer.close();

    }
}

```

测试：

①在 hadoop102 上开启 Kafka 消费者。

②在  IDEA 中执行代码，观察  hadoop102 控制台中是否接收到消息。

#### 3）案例二

`没有指明  partition 值但有  key `的情况下，将  key 的  `hash` 值与  topic 的  `partition 数进行取余`得到 partition 值。

```java
package com.atguigu.kafka.producer;

import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

/**
 * 按照key将数据发送到指定的分区
 * @author shkstart
 * @create 2022 - 04 - 19 - 17:10
 */
public class producerPartiton {
    public static void main(String[] args) {
        //2.创建生产者配置对象
        Properties properties = new Properties();
        //配置对象添加配置信息
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092");
        //key,value序列化（必要条件）
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        //1.创建kafka生产者对象
        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(properties);
        //3.调用send方法，发送信息
        for (int i=0;i<=5;i++){
            //根据指定的分区，将数据传输到指定的分区
            producer.send(new ProducerRecord<>("first", 1,"atguigu", "atguigu" + i), new Callback() {
            //只有key根据key的hash值 确定分区的情况
            // producer.send(new ProducerRecord<>("first", "atguigu", "atguigu" + i), new Callback() {
                @Override
                public void onCompletion(RecordMetadata recordMetadata, Exception e) {
                    if (e==null){
                        System.out.println("主题是"+recordMetadata.topic()+"分区为"+recordMetadata.partition());
                    }
                }
            });
        }
        //4.关闭资源
        producer.close();

    }
}

```

测试：

①key="a"时，在控制台查看结果。

②key="b"时，在控制台查看结果。

③key="D"时，在控制台查看结果。



### 4.3 自定义分区器

#### 1）需求

例如我们实现一个分区器实现，发送过来的数据中如果包含   atguigu，就发往   0 号分区， 不包含 atguigu，就发往 1 号分区。

#### 2）实现步骤

（1）定义类实现 Partitioner 接口。
       （2）重写 partition()方法。

```java
package com.atguigu.kafka.producer;

import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;

import java.util.Map;

/**
 * @author shkstart
 * @create 2022 - 04 - 20 - 14:06
 */
public class myPartition implements Partitioner {
    /**
     * 重写的核心方法
     *
     * @param s
     * @param o       key
     * @param bytes   key的序列化字节
     * @param o1      value
     * @param bytes1  value的序列化字节
     * @param cluster 集群元数据可以查看分区信息
     * @return 返回的是数据进入的分区 码
     */
    @Override
    public int partition(String s, Object o, byte[] bytes, Object o1, byte[] bytes1, Cluster cluster) {
        String value = o1.toString();
        int partition;
        if (value.contains("atguigu")) {
            partition = 0;
        } else {
            partition = 1;
        }
        return partition;
    }

    @Override
    public void close() {

    }

    @Override
    public void configure(Map<String, ?> map) {

    }
}

```

（3）使用分区器的方法，在生产者的配置中添加分区器参数。

```java
package com.atguigu.kafka.producer;

import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

/**
 * @author shkstart
 * @create 2022 - 04 - 19 - 17:10
 */
public class myPartitionProducer {
    public static void main(String[] args) {
        //2.创建生产者配置对象
        Properties properties = new Properties();
        //配置对象添加配置信息
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092");
        //key,value序列化（必要条件）
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        
        
        //使用自定义的分区器
        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, "com.atguigu.kafka.producer.myPartition");

        
        //1.创建kafka生产者对象
        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(properties);
        //3.调用send方法，发送信息
        for (int i=0;i<=5;i++){
            producer.send(new ProducerRecord<>("first", "atguigu" + i), new Callback() {
                @Override
                public void onCompletion(RecordMetadata recordMetadata, Exception e) {
                    if (e==null){
                        System.out.println(recordMetadata.topic()+" "+recordMetadata.partition());
                    }
                }
            });
        }
        //4.关闭资源
        producer.close();
    }
}

```

（4）测试

①在 hadoop102 上开启 Kafka 消费者。

②在  IDEA 控制台观察回调信息。



## 5.生产经验——生产者如何提高吞吐量

![](D:\typroa.md\image\Snipaste_2022-04-21_16-55-53.png)

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

/**
 * @author shkstart
 * @create 2022 - 04 - 20 - 17:25
 */
public class CustomProducerParameters {
    public static void main(String[] args) {
        //创建配置对象
        Properties properties = new Properties();
        //创建连接
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092");
        //序列化key和value
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

		//更改相关参数
		
//batch.size：批次大小，默认 16K
        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);

// linger.ms：等待时间，默认  0
        properties.put(ProducerConfig.LINGER_MS_CONFIG, 1);

// RecordAccumulator：缓冲区大小，默认  32M：buffer.memory
        properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);
        
        // compression.type：压缩，默认none，可配置值gzip、snappy、lz4和 zstd
properties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG,"snappy");
        
        //创建kafka生产者对象
        KafkaProducer<String, String> producer = new KafkaProducer<String, String>(properties);
        //发送数据
        for (int i = 0; i <= 5; i++) {
            producer.send(new ProducerRecord<>("first", "atguigu" + i));
        }
        //关闭资源
        producer.close();
    }


}
```

测试：

①在 hadoop102 上开启 Kafka 消费者。

②在  IDEA 中执行代码，观察  hadoop102 控制台中是否接收到消息。

## 6.生产经验——数据可靠性

### 0）回顾发送流程

![](D:\typroa.md\image\Snipaste_2022-04-21_17-00-10.png)

### 1）ack 应答原理

![](D:\typroa.md\image\Snipaste_2022-04-21_17-00-43.png)

![](D:\typroa.md\image\Snipaste_2022-04-21_17-03-03.png)

![](D:\typroa.md\image\Snipaste_2022-04-21_17-08-05.png)

### 2）代码配置

```java
package com.atguigu.kafka.producer;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import java.util.Properties;
public class CustomProducerAck {
public    static void main(String[] args) throws InterruptedException {
// 1. 创建  kafka生产者的配置对象
Properties properties = new Properties();
// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers
properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, 
"hadoop102:9092");
// key,value 序列化（必须）：key.serializer，value.serializer 
properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
StringSerializer.class.getName());
properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, 
StringSerializer.class.getName());
    
// 设置 acks
properties.put(ProducerConfig.ACKS_CONFIG, "all"); 
    
// 重试次数 retries，默认是 int最大值，2147483647
properties.put(ProducerConfig.RETRIES_CONFIG, 3);
// 3. 创建  kafka生产者对象
KafkaProducer<String,   String>   kafkaProducer   =   new 
KafkaProducer<String, String>(properties);
// 4. 调用  send方法,发送消息 
for (int i = 0; i < 5; i++) {
kafkaProducer.send(new 
ProducerRecord<>("first","atguigu " + i));
}
// 5. 关闭资源 
kafkaProducer.close();
} 
}
```

## 7.生产经验——数据去重

解决ack=all出现数据重复的问题

至少一次（At Least Once）= `ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2`

最多一次（At Most Once）= `ACK级别设置为0`

总结：

At Least Once可以保证数据不丢失，但是`不能保证数据不重复；` 

At Most Once可以保证数据不重复，但是`不能保证数据不丢失。`

精确一次（Exactly  Once）：对于一些非常重要的信息，比如和钱相关的数据，要求数据`既不能重复也不丢失`。Kafka  0.11版本以后，引入了一项重大特性：`幂等性和事务`。

### 7.1幂等性

#### 1）幂等性原理

**幂等性**就是指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复。 

**精确一次（Exactly Once）  = 幂等性 + 至少一次（ ack=-1 +  分区副本数>=2 +  ISR最小副本数量>=2） 。**

重复数据的判断标准：具有`<PID,  Partition,  SeqNumber>`相同主键的消息提交时，Broker只会持久化一条。其中`PID是Kafka每次重启都会分配一个新的；Partition 表示分区号；Sequence Number是单调自增的`。

所以`幂等性只能保证的是在单分区单会话内不重复`。

#### 2）如何使用幂等性

开启参数 enable.idempotence `默认为 true`，false 关闭。

```java
properties.put(ProducerConfig.enable.idempotence, "true");
```

### 7.2生产者事务

#### 1）Kafka 事务原理

![](D:\typroa.md\image\Snipaste_2022-04-21_17-30-30.png)

#### 2）Kafka 的事务一共有如下  5 个 API

```java
// 1 初始化事务
void initTransactions(); 
// 2 开启事务
void beginTransaction() throws ProducerFencedException; 
// 3 在事务内提交已经消费的偏移量（主要用于消费者）
void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,
ProducerFencedException; 
// 4 提交事务
void commitTransaction() throws ProducerFencedException; 
// 5 放弃事务（类似于回滚事务的操作）
void abortTransaction() throws ProducerFencedException;
```

#### 3）单个  Producer，使用事务保证消息的仅一次发送

```java
package com.atguigu.kafka.producer;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import java.util.Properties;
public class CustomProducerTransactions {
public    static void main(String[] args) throws InterruptedException {
// 1. 创建  kafka生产者的配置对象
Properties properties = new Properties(); 
// 2. 给 kafka 配置对象添加配置信息
properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,
"hadoop102:9092");
// key,value 序列化
properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG 
StringSerializer.class.getName());
properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, 
StringSerializer.class.getName());
// 设置事务 id（必须），事务 id 任意起名
properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, 
"transaction_id_0");
// 3. 创建  kafka生产者对象
KafkaProducer<String,   String>   kafkaProducer   =   new 
KafkaProducer<String, String>(properties);
// 初始化事务
kafkaProducer.initTransactions(); 
// 开启事务
kafkaProducer.beginTransaction(); 
try {
// 4. 调用 send 方法,发送消息 
for (int i = 0; i < 5; i++) {
// 发送消息
kafkaProducer.send(new  ProducerRecord<>("first", 
"atguigu " + i));
}
//            int i = 1 / 0;
// 提交事务
kafkaProducer.commitTransaction(); 
} catch (Exception e) {
// 终止事务
kafkaProducer.abortTransaction(); 
} finally {
// 5. 关闭资源 
kafkaProducer.close();
} 
}
}
```

## 8.生产经验——数据有序

![](D:\typroa.md\image\Snipaste_2022-04-21_17-36-43.png)

在消费者端重新将发送来的数据进行排序。



## 9.生产经验——数据乱序

![](D:\typroa.md\image\Snipaste_2022-04-21_17-37-09.png)

kafka集群在接收request3时 （request1、2接收确定不是重复数据，就会落盘），如果出现了错误，集群向生产者发送信息，生产者重新发送request3，同时集群接收request4、5但是由于和已接收的request顺序连接不上，会暂时的将其缓存继续接收下一个，直到缓存大于5，Sequence Number在缓存区将request3、4 、5重新排序然后将request（3、4 、5）落盘。

